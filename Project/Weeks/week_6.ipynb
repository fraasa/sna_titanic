{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instructions\n",
    "0) Treat your graph as undirected and unweighted. Delete loops and work on the resulting largest\n",
    "connected component.\n",
    "1) Implement the following three techniques for community detection:\n",
    "a) Bridge removal (pick the partition with the highest modularity), b) Modularity optimization, c) Label\n",
    "propagation.\n",
    "In this case, you are allowed to use built-in functions from NetworkX.\n",
    "2) Compare the results of each technique in terms of: a) number of detected clusters, b) cluster size\n",
    "distribution, c) computational time, e) modularity, f) other aspects you consider relevant, if any. Results\n",
    "should be presented in a table.\n",
    "3) Give an interpretation to the differences and similarities between the three resulting partitions, and\n",
    "discuss which one you think is the best and why.\n",
    "4) Provide a visualization for the partition you decided to be the best using Gephi.\n",
    "5) Optional: for each pair of partitions compute the NMI between them and discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the graph from CSV files\n",
    "def load_graph(nodes_file_path, edges_file_path):\n",
    "    G = nx.DiGraph()\n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "             source, target = row['Source'], row['Target']\n",
    "             if source != target:  # Exclude self-loops\n",
    "                G.add_edge(source, target, weight=1)\n",
    "                G.add_edge(target, source, weight=1)  # For undirected links          \n",
    "\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community\n",
    "\n",
    "def get_largest_connected_component(G):\n",
    "    # Convert to undirected graph to find connected components\n",
    "    undirected_G = G.to_undirected()\n",
    "    \n",
    "    # Get the largest connected component\n",
    "    components = list(nx.connected_components(undirected_G))\n",
    "    \n",
    "    if not components:\n",
    "        # If the graph is empty, return an empty graph\n",
    "        return nx.Graph()\n",
    "    \n",
    "    largest_component = max(components, key=len)\n",
    "    return G.subgraph(largest_component)\n",
    "\n",
    "def community_detection_bridge_removal(G):\n",
    "    # Use Girvan-Newman algorithm for bridge removal\n",
    "    communities = list(community.girvan_newman(G))\n",
    "    best_partition = max(communities, key=lambda x: community.modularity(G, x))\n",
    "    return best_partition\n",
    "\n",
    "def community_detection_modularity_optimization(G):\n",
    "    # Use greedy modularity optimization\n",
    "    communities = list(community.greedy_modularity_communities(G))\n",
    "    partition = {node: i for i, community in enumerate(communities) for node in community}\n",
    "    return partition\n",
    "\n",
    "def community_detection_label_propagation(G):\n",
    "    # Use label propagation algorithm\n",
    "    partition = community.label_propagation_communities(G)\n",
    "    return partition\n",
    "\n",
    "# Load the graph\n",
    "G = load_graph('D:/Github/sna_titanic/Project/Graph/nodes.csv', 'D:/Github/sna_titanic/Project/Graph/edges.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate_results(partition, ground_truth=None, G=None):\n",
    "    # Evaluate the detected partition against ground truth or using other metrics\n",
    "\n",
    "    num_clusters = len(set(partition.values()))\n",
    "\n",
    "    cluster_sizes = Counter(partition.values())\n",
    "\n",
    "    modularity = community.modularity(G, [set(partition.keys()) - set(partition[cluster]) for cluster in set(partition.values())])\n",
    "\n",
    "    evaluation_metrics = {\n",
    "        'Number of Clusters': num_clusters,\n",
    "        'Cluster Sizes': cluster_sizes,\n",
    "        'Modularity': modularity\n",
    "        # Add more metrics as needed\n",
    "    }\n",
    "\n",
    "    return evaluation_metrics\n",
    "\n",
    "def compare_techniques(G):\n",
    "    # Evaluate each community detection technique and compare the results\n",
    "\n",
    "    # Bridge removal\n",
    "    start_time = time.time()\n",
    "    bridge_removal_partition = community_detection_bridge_removal(G)\n",
    "    bridge_removal_metrics = evaluate_results(bridge_removal_partition)\n",
    "    bridge_removal_time = time.time() - start_time\n",
    "\n",
    "    # Modularity optimization\n",
    "    start_time = time.time()\n",
    "    modularity_optimization_partition = community_detection_modularity_optimization(G)\n",
    "    modularity_optimization_metrics = evaluate_results(modularity_optimization_partition)\n",
    "    modularity_optimization_time = time.time() - start_time\n",
    "\n",
    "    # Label propagation\n",
    "    start_time = time.time()\n",
    "    label_propagation_partition = community_detection_label_propagation(G)\n",
    "    label_propagation_metrics = evaluate_results(label_propagation_partition)\n",
    "    label_propagation_time = time.time() - start_time\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Bridge Removal Results:\", bridge_removal_metrics, \"Time:\", bridge_removal_time)\n",
    "    print(\"Modularity Optimization Results:\", modularity_optimization_metrics, \"Time:\", modularity_optimization_time)\n",
    "    print(\"Label Propagation Results:\", label_propagation_metrics, \"Time:\", label_propagation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import time\n",
    "from networkx.algorithms import community\n",
    "\n",
    "# Function to load the graph\n",
    "def load_graph(nodes_file_path, edges_file_path):\n",
    "    G = nx.DiGraph()\n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_edge(row['Source'], row['Target'], weight=1)\n",
    "            G.add_edge(row['Target'], row['Source'], weight=1)  # For undirected links\n",
    "\n",
    "    return G\n",
    "\n",
    "# Function to convert partition to communities format\n",
    "def convert_partition_to_communities(partition):\n",
    "    communities = {}\n",
    "    for node, community in partition.items():\n",
    "        if community not in communities:\n",
    "            communities[community] = set()\n",
    "        communities[community].add(node)\n",
    "    return list(communities.values())\n",
    "\n",
    "# Bridge Removal using Girvan-Newman Algorithm\n",
    "def community_detection_bridge_removal(G):\n",
    "    communities_generator = community.girvan_newman(G)\n",
    "    best_partition = None\n",
    "    best_modularity = -1\n",
    "\n",
    "    for communities in communities_generator:\n",
    "        modularity = community.modularity(G, communities)\n",
    "        if modularity > best_modularity:\n",
    "            best_modularity = modularity\n",
    "            best_partition = communities\n",
    "\n",
    "    partition_dict = {node: i for i, comm in enumerate(best_partition) for node in comm}\n",
    "    return partition_dict, best_modularity\n",
    "\n",
    "# Modularity Optimization using Greedy Algorithm\n",
    "def community_detection_modularity_optimization(G):\n",
    "    communities = community.greedy_modularity_communities(G)\n",
    "    partition = {node: i for i, comm in enumerate(communities) for node in comm}\n",
    "    return partition\n",
    "\n",
    "# Label Propagation\n",
    "def community_detection_label_propagation(G):\n",
    "    communities = community.label_propagation_communities(G)\n",
    "    partition = {node: i for i, comm in enumerate(communities) for node in comm}\n",
    "    return partition\n",
    "\n",
    "# Load the graph from the provided CSV files\n",
    "nodes_file_path = 'D:/Github/sna_titanic/Project/Graph/nodes.csv'\n",
    "edges_file_path = 'D:/Github/sna_titanic/Project/Graph/edges.csv'\n",
    "G = load_graph(nodes_file_path, edges_file_path)\n",
    "\n",
    "# Convert the graph to undirected and remove self-loops\n",
    "G_undirected = G.to_undirected()\n",
    "G_undirected.remove_edges_from(nx.selfloop_edges(G_undirected))\n",
    "\n",
    "# Extract the largest connected component\n",
    "largest_cc = max(nx.connected_components(G_undirected), key=len)\n",
    "G_largest_cc = G_undirected.subgraph(largest_cc)\n",
    "\n",
    "# Apply Bridge Removal Method\n",
    "start_time = time.time()\n",
    "bridge_removal_partition, bridge_removal_modularity = community_detection_bridge_removal(G_largest_cc)\n",
    "bridge_removal_time = time.time() - start_time\n",
    "\n",
    "# Apply Modularity Optimization Method\n",
    "start_time = time.time()\n",
    "modularity_optimization_partition = community_detection_modularity_optimization(G_largest_cc)\n",
    "modularity_optimization_time = time.time() - start_time\n",
    "modularity_optimization_communities = convert_partition_to_communities(modularity_optimization_partition)\n",
    "modularity_optimization_modularity = community.modularity(G_largest_cc, modularity_optimization_communities)\n",
    "\n",
    "# Apply Label Propagation Method\n",
    "start_time = time.time()\n",
    "label_propagation_partition = community_detection_label_propagation(G_largest_cc)\n",
    "label_propagation_time = time.time() - start_time\n",
    "label_propagation_communities = convert_partition_to_communities(label_propagation_partition)\n",
    "label_propagation_modularity = community.modularity(G_largest_cc, label_propagation_communities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridge Removal Method:\n",
      "Time taken:  1.2483339309692383\n",
      "Modularity:  0.210517779443183\n",
      "Partition:  {'5099903': 0, '5100134': 0, '5102317': 0, '5104295': 0, '5097875': 0, '5099090': 0, '5098619': 0, '5106033': 0, '5097941': 0, '5099096': 0, '5098545': 0, '5097915': 0, '5100274': 0, '5098095': 0, '5097894': 0, '5102690': 0, '5102924': 0, '5103789': 0, '5097979': 0, '5100333': 0, '5102237': 0, '5097316': 0, '5101061': 0, '5098583': 0, '5098041': 0, '5099267': 0, '5100327': 0, '5097994': 0, '5099110': 0, '5098606': 0, '5102939': 0, '5102267': 0, '5100235': 0, '5098717': 0, '5098463': 0, '5097262': 1, '5097320': 1, '5096932': 1, '5097505': 1, '5097212': 1, '5099349': 1, '5096948': 1, '5097296': 1, '5096969': 1, '5097161': 1, '5098088': 2, '5098128': 2, '5098193': 2, '5098082': 2, '5102009': 3, '5101285': 3, '5101840': 3, '5101981': 3, '5101998': 3, '5098242': 3, '5101750': 4, '5101041': 4, '5098541': 5, '5098267': 6, '5103242': 7, '5103072': 8, '5102841': 9, '5105174': 10, '5105151': 10, '5099499': 11, '5105104': 12, '5102992': 13, '5103330': 14, '5102617': 15, '5098417': 16}\n",
      "\n",
      "\n",
      "Modularity Optimization Method:\n",
      "Time taken:  0.01599860191345215\n",
      "Modularity:  0.32898401583874903\n",
      "Partition:  {'5098541': 0, '5104295': 0, '5102317': 0, '5101061': 0, '5098082': 0, '5098583': 0, '5098193': 0, '5105151': 0, '5099499': 0, '5098128': 0, '5101041': 0, '5098545': 0, '5102267': 0, '5101750': 0, '5103072': 0, '5098088': 0, '5105174': 0, '5098095': 0, '5097894': 1, '5102690': 1, '5100134': 1, '5099903': 1, '5102924': 1, '5103789': 1, '5102992': 1, '5097979': 1, '5102237': 1, '5102841': 1, '5097875': 1, '5097994': 1, '5097941': 1, '5099096': 1, '5102939': 1, '5097915': 1, '5098463': 1, '5097262': 2, '5097320': 2, '5097505': 2, '5096948': 2, '5097316': 2, '5105104': 2, '5099267': 2, '5098041': 2, '5098417': 2, '5103330': 2, '5096932': 2, '5106033': 2, '5097212': 2, '5099349': 2, '5097296': 2, '5096969': 2, '5097161': 2, '5100274': 3, '5100327': 3, '5099110': 3, '5098606': 3, '5100333': 3, '5103242': 3, '5100235': 3, '5102617': 3, '5099090': 3, '5098619': 3, '5098267': 4, '5102009': 4, '5101285': 4, '5101840': 4, '5101981': 4, '5098242': 4, '5101998': 4, '5098717': 4}\n",
      "\n",
      "\n",
      "Label Propagation Method:\n",
      "Time taken:  0.007999658584594727\n",
      "Modularity:  0.16695562689455373\n",
      "Partition:  {'5100134': 0, '5099903': 0, '5097320': 0, '5102992': 0, '5101981': 0, '5102317': 0, '5104295': 0, '5097875': 0, '5099090': 0, '5098619': 0, '5105104': 0, '5106033': 0, '5097941': 0, '5099096': 0, '5099499': 0, '5098545': 0, '5097915': 0, '5098095': 0, '5100274': 0, '5097894': 0, '5102690': 0, '5102924': 0, '5103789': 0, '5098541': 0, '5097979': 0, '5100333': 0, '5102237': 0, '5103242': 0, '5097316': 0, '5101061': 0, '5102841': 0, '5098583': 0, '5098041': 0, '5099267': 0, '5098417': 0, '5103330': 0, '5097994': 0, '5098267': 0, '5100327': 0, '5099110': 0, '5098606': 0, '5098128': 0, '5102939': 0, '5101041': 0, '5097296': 0, '5100235': 0, '5102267': 0, '5101750': 0, '5103072': 0, '5098717': 0, '5102617': 0, '5098463': 0, '5097262': 1, '5096932': 1, '5097505': 1, '5097212': 1, '5099349': 1, '5096948': 1, '5096969': 1, '5097161': 1, '5102009': 2, '5101285': 2, '5101840': 2, '5101998': 2, '5098242': 2, '5105174': 3, '5105151': 3, '5098088': 4, '5098193': 4, '5098082': 4}\n"
     ]
    }
   ],
   "source": [
    "# Print the results of the Bridge Removal Method\n",
    "print(\"Bridge Removal Method:\")\n",
    "print(\"Time taken: \", bridge_removal_time)\n",
    "print(\"Modularity: \", bridge_removal_modularity)\n",
    "print(\"Partition: \", bridge_removal_partition)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the results of the Modularity Optimization Method\n",
    "print(\"Modularity Optimization Method:\")\n",
    "print(\"Time taken: \", modularity_optimization_time)\n",
    "print(\"Modularity: \", modularity_optimization_modularity)\n",
    "print(\"Partition: \", modularity_optimization_partition)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the results of the Label Propagation Method\n",
    "print(\"Label Propagation Method:\")\n",
    "print(\"Time taken: \", label_propagation_time)\n",
    "print(\"Modularity: \", label_propagation_modularity)\n",
    "print(\"Partition: \", label_propagation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Analysis and Interpretation of Results\n",
    "\n",
    "- **Bridge Removal**: \n",
    "  - Detected 17 clusters with a diverse size distribution.\n",
    "  - Computational Time: 4.234 seconds.\n",
    "  - Modularity: 0.211.\n",
    "\n",
    "- **Modularity Optimization**: \n",
    "  - Detected 5 clusters, more balanced in size.\n",
    "  - Computational Time: 0.112 seconds.\n",
    "  - Modularity: 0.329.\n",
    "\n",
    "- **Label Propagation**: \n",
    "  - Also detected 5 clusters but with one dominant large cluster.\n",
    "  - Computational Time: 0.032 seconds.\n",
    "  - Modularity: 0.167.\n",
    "\n",
    "Given these results, Modularity Optimization appears to be the best method due to its high modularity, balanced cluster sizes, and reasonable computational time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Method': ['Bridge Removal', 'Modularity Optimization', 'Label Propagation'],\n",
       " 'Number of Clusters': [17, 5, 5],\n",
       " 'Cluster Size Distribution': [Counter({0: 35,\n",
       "           1: 10,\n",
       "           3: 6,\n",
       "           2: 4,\n",
       "           4: 2,\n",
       "           10: 2,\n",
       "           5: 1,\n",
       "           6: 1,\n",
       "           7: 1,\n",
       "           8: 1,\n",
       "           9: 1,\n",
       "           11: 1,\n",
       "           12: 1,\n",
       "           13: 1,\n",
       "           14: 1,\n",
       "           15: 1,\n",
       "           16: 1}),\n",
       "  Counter({0: 18, 1: 17, 2: 17, 3: 10, 4: 8}),\n",
       "  Counter({0: 52, 1: 8, 2: 5, 4: 3, 3: 2})],\n",
       " 'Computational Time (seconds)': [1.2483339309692383,\n",
       "  0.01599860191345215,\n",
       "  0.007999658584594727],\n",
       " 'Modularity': [0.210517779443183, 0.32898401583874903, 0.16695562689455373]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_cluster_sizes(partition):\n",
    "    \"\"\"\n",
    "    Calculate the sizes of clusters in a partition.\n",
    "    \"\"\"\n",
    "    cluster_sizes = Counter(partition.values())\n",
    "    return cluster_sizes\n",
    "\n",
    "# Calculate cluster sizes for each method\n",
    "bridge_removal_cluster_sizes = get_cluster_sizes(bridge_removal_partition)\n",
    "modularity_optimization_cluster_sizes = get_cluster_sizes(modularity_optimization_partition)\n",
    "label_propagation_cluster_sizes = get_cluster_sizes(label_propagation_partition)\n",
    "\n",
    "# Prepare data for comparison table\n",
    "comparison_data = {\n",
    "    'Method': ['Bridge Removal', 'Modularity Optimization', 'Label Propagation'],\n",
    "    'Number of Clusters': [len(bridge_removal_cluster_sizes), len(modularity_optimization_cluster_sizes), len(label_propagation_cluster_sizes)],\n",
    "    'Cluster Size Distribution': [bridge_removal_cluster_sizes, modularity_optimization_cluster_sizes, label_propagation_cluster_sizes],\n",
    "    'Computational Time (seconds)': [bridge_removal_time, modularity_optimization_time, label_propagation_time],\n",
    "    'Modularity': [bridge_removal_modularity, modularity_optimization_modularity, label_propagation_modularity]\n",
    "}\n",
    "\n",
    "comparison_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import time\n",
    "from networkx.algorithms import community\n",
    "\n",
    "# Function to load the graph\n",
    "def load_graph(nodes_file_path, edges_file_path):\n",
    "    G = nx.DiGraph()\n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_edge(row['Source'], row['Target'], weight=1)\n",
    "            G.add_edge(row['Target'], row['Source'], weight=1)  # For undirected links\n",
    "\n",
    "    return G\n",
    "\n",
    "# Function to convert partition to communities format\n",
    "def convert_partition_to_communities(partition):\n",
    "    communities = {}\n",
    "    for node, community in partition.items():\n",
    "        if community not in communities:\n",
    "            communities[community] = set()\n",
    "        communities[community].add(node)\n",
    "    return list(communities.values())\n",
    "\n",
    "# Bridge Removal using Girvan-Newman Algorithm\n",
    "def community_detection_bridge_removal(G):\n",
    "    communities_generator = community.girvan_newman(G)\n",
    "    best_partition = None\n",
    "    best_modularity = -1\n",
    "\n",
    "    for communities in communities_generator:\n",
    "        modularity = community.modularity(G, communities)\n",
    "        if modularity > best_modularity:\n",
    "            best_modularity = modularity\n",
    "            best_partition = communities\n",
    "\n",
    "    partition_dict = {node: i for i, comm in enumerate(best_partition) for node in comm}\n",
    "    return partition_dict, best_modularity\n",
    "\n",
    "# Modularity Optimization using Greedy Algorithm\n",
    "def community_detection_modularity_optimization(G):\n",
    "    communities = community.greedy_modularity_communities(G)\n",
    "    partition = {node: i for i, comm in enumerate(communities) for node in comm}\n",
    "    return partition\n",
    "\n",
    "# Label Propagation\n",
    "def community_detection_label_propagation(G):\n",
    "    communities = community.label_propagation_communities(G)\n",
    "    partition = {node: i for i, comm in enumerate(communities) for node in comm}\n",
    "    return partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the graph from the provided CSV files\n",
    "nodes_file_path = 'D:/Github/sna_titanic/Project/Graph/nodes.csv'\n",
    "edges_file_path = 'D:/Github/sna_titanic/Project/Graph/edges.csv'\n",
    "G = load_graph(nodes_file_path, edges_file_path)\n",
    "\n",
    "# Convert the graph to undirected and remove self-loops\n",
    "G_undirected = G.to_undirected()\n",
    "G_undirected.remove_edges_from(nx.selfloop_edges(G_undirected))\n",
    "\n",
    "# Extract the largest connected component\n",
    "largest_cc = max(nx.connected_components(G_undirected), key=len)\n",
    "G_largest_cc = G_undirected.subgraph(largest_cc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Comparison of Community Detection Techniques\n",
    "\n",
    "We will compare the results of the three community detection techniques based on:\n",
    "- Number of Detected Clusters\n",
    "- Cluster Size Distribution\n",
    "- Computational Time\n",
    "- Modularity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply Bridge Removal Method\n",
    "start_time = time.time()\n",
    "bridge_removal_partition, bridge_removal_modularity = community_detection_bridge_removal(G_largest_cc)\n",
    "bridge_removal_time = time.time() - start_time\n",
    "\n",
    "# Apply Modularity Optimization Method\n",
    "start_time = time.time()\n",
    "modularity_optimization_partition = community_detection_modularity_optimization(G_largest_cc)\n",
    "modularity_optimization_time = time.time() - start_time\n",
    "modularity_optimization_communities = convert_partition_to_communities(modularity_optimization_partition)\n",
    "modularity_optimization_modularity = community.modularity(G_largest_cc, modularity_optimization_communities)\n",
    "\n",
    "# Apply Label Propagation Method\n",
    "start_time = time.time()\n",
    "label_propagation_partition = community_detection_label_propagation(G_largest_cc)\n",
    "label_propagation_time = time.time() - start_time\n",
    "label_propagation_communities = convert_partition_to_communities(label_propagation_partition)\n",
    "label_propagation_modularity = community.modularity(G_largest_cc, label_propagation_communities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridge Removal Method:\n",
      "Time taken:  1.2483339309692383\n",
      "Modularity:  0.210517779443183\n",
      "Partition:  {'5099903': 0, '5100134': 0, '5102317': 0, '5104295': 0, '5097875': 0, '5099090': 0, '5098619': 0, '5106033': 0, '5097941': 0, '5099096': 0, '5098545': 0, '5097915': 0, '5100274': 0, '5098095': 0, '5097894': 0, '5102690': 0, '5102924': 0, '5103789': 0, '5097979': 0, '5100333': 0, '5102237': 0, '5097316': 0, '5101061': 0, '5098583': 0, '5098041': 0, '5099267': 0, '5100327': 0, '5097994': 0, '5099110': 0, '5098606': 0, '5102939': 0, '5102267': 0, '5100235': 0, '5098717': 0, '5098463': 0, '5097262': 1, '5097320': 1, '5096932': 1, '5097505': 1, '5097212': 1, '5099349': 1, '5096948': 1, '5097296': 1, '5096969': 1, '5097161': 1, '5098088': 2, '5098128': 2, '5098193': 2, '5098082': 2, '5102009': 3, '5101285': 3, '5101840': 3, '5101981': 3, '5101998': 3, '5098242': 3, '5101750': 4, '5101041': 4, '5098541': 5, '5098267': 6, '5103242': 7, '5103072': 8, '5102841': 9, '5105174': 10, '5105151': 10, '5099499': 11, '5105104': 12, '5102992': 13, '5103330': 14, '5102617': 15, '5098417': 16}\n",
      "\n",
      "\n",
      "Modularity Optimization Method:\n",
      "Time taken:  0.01599860191345215\n",
      "Modularity:  0.32898401583874903\n",
      "Partition:  {'5098541': 0, '5104295': 0, '5102317': 0, '5101061': 0, '5098082': 0, '5098583': 0, '5098193': 0, '5105151': 0, '5099499': 0, '5098128': 0, '5101041': 0, '5098545': 0, '5102267': 0, '5101750': 0, '5103072': 0, '5098088': 0, '5105174': 0, '5098095': 0, '5097894': 1, '5102690': 1, '5100134': 1, '5099903': 1, '5102924': 1, '5103789': 1, '5102992': 1, '5097979': 1, '5102237': 1, '5102841': 1, '5097875': 1, '5097994': 1, '5097941': 1, '5099096': 1, '5102939': 1, '5097915': 1, '5098463': 1, '5097262': 2, '5097320': 2, '5097505': 2, '5096948': 2, '5097316': 2, '5105104': 2, '5099267': 2, '5098041': 2, '5098417': 2, '5103330': 2, '5096932': 2, '5106033': 2, '5097212': 2, '5099349': 2, '5097296': 2, '5096969': 2, '5097161': 2, '5100274': 3, '5100327': 3, '5099110': 3, '5098606': 3, '5100333': 3, '5103242': 3, '5100235': 3, '5102617': 3, '5099090': 3, '5098619': 3, '5098267': 4, '5102009': 4, '5101285': 4, '5101840': 4, '5101981': 4, '5098242': 4, '5101998': 4, '5098717': 4}\n",
      "\n",
      "\n",
      "Label Propagation Method:\n",
      "Time taken:  0.007999658584594727\n",
      "Modularity:  0.16695562689455373\n",
      "Partition:  {'5100134': 0, '5099903': 0, '5097320': 0, '5102992': 0, '5101981': 0, '5102317': 0, '5104295': 0, '5097875': 0, '5099090': 0, '5098619': 0, '5105104': 0, '5106033': 0, '5097941': 0, '5099096': 0, '5099499': 0, '5098545': 0, '5097915': 0, '5098095': 0, '5100274': 0, '5097894': 0, '5102690': 0, '5102924': 0, '5103789': 0, '5098541': 0, '5097979': 0, '5100333': 0, '5102237': 0, '5103242': 0, '5097316': 0, '5101061': 0, '5102841': 0, '5098583': 0, '5098041': 0, '5099267': 0, '5098417': 0, '5103330': 0, '5097994': 0, '5098267': 0, '5100327': 0, '5099110': 0, '5098606': 0, '5098128': 0, '5102939': 0, '5101041': 0, '5097296': 0, '5100235': 0, '5102267': 0, '5101750': 0, '5103072': 0, '5098717': 0, '5102617': 0, '5098463': 0, '5097262': 1, '5096932': 1, '5097505': 1, '5097212': 1, '5099349': 1, '5096948': 1, '5096969': 1, '5097161': 1, '5102009': 2, '5101285': 2, '5101840': 2, '5101998': 2, '5098242': 2, '5105174': 3, '5105151': 3, '5098088': 4, '5098193': 4, '5098082': 4}\n"
     ]
    }
   ],
   "source": [
    "# Print the results of the Bridge Removal Method\n",
    "print(\"Bridge Removal Method:\")\n",
    "print(\"Time taken: \", bridge_removal_time)\n",
    "print(\"Modularity: \", bridge_removal_modularity)\n",
    "print(\"Partition: \", bridge_removal_partition)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the results of the Modularity Optimization Method\n",
    "print(\"Modularity Optimization Method:\")\n",
    "print(\"Time taken: \", modularity_optimization_time)\n",
    "print(\"Modularity: \", modularity_optimization_modularity)\n",
    "print(\"Partition: \", modularity_optimization_partition)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the results of the Label Propagation Method\n",
    "print(\"Label Propagation Method:\")\n",
    "print(\"Time taken: \", label_propagation_time)\n",
    "print(\"Modularity: \", label_propagation_modularity)\n",
    "print(\"Partition: \", label_propagation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Analysis and Interpretation of Results\n",
    "\n",
    "- **Bridge Removal**: \n",
    "  - Detected 17 clusters with a diverse size distribution.\n",
    "  - Computational Time: 4.234 seconds.\n",
    "  - Modularity: 0.211.\n",
    "\n",
    "- **Modularity Optimization**: \n",
    "  - Detected 5 clusters, more balanced in size.\n",
    "  - Computational Time: 0.112 seconds.\n",
    "  - Modularity: 0.329.\n",
    "\n",
    "- **Label Propagation**: \n",
    "  - Also detected 5 clusters but with one dominant large cluster.\n",
    "  - Computational Time: 0.032 seconds.\n",
    "  - Modularity: 0.167.\n",
    "\n",
    "Given these results, Modularity Optimization appears to be the best method due to its high modularity, balanced cluster sizes, and reasonable computational time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison of the results for each community detection technique is as follows:\n",
    "\n",
    "| Method                    | Number of Clusters | Cluster Size Distribution                                  | Computational Time (seconds) | Modularity  |\n",
    "|---------------------------|--------------------|------------------------------------------------------------|-----------------------------|-------------|\n",
    "| Bridge Removal            | 17                 | {0: 35, 1: 10, 2: 4, ..., 16: 1}                           | 4.234                       | 0.211       |\n",
    "| Modularity Optimization   | 5                  | {0: 18, 1: 17, 2: 17, 3: 10, 4: 8}                          | 0.112                       | 0.329       |\n",
    "| Label Propagation         | 5                  | {0: 52, 1: 8, 2: 5, 3: 2, 4: 3}                             | 0.032                       | 0.167       |\n",
    "\n",
    "### Analysis and Interpretation (Task 3)\n",
    "\n",
    "- **Bridge Removal:** This method detected the highest number of clusters, indicating a finer partitioning of the network. However, it also had the longest computational time, suggesting it might be less efficient for larger networks. The modularity is moderate, which implies a reasonable but not optimal community structure.\n",
    "- **Modularity Optimization:** This method found a smaller number of larger clusters, with the highest modularity score among the three. This suggests that it was able to detect a community structure that aligns well with the network's inherent modular structure. It also offers a good balance between computational efficiency and the quality of community detection.\n",
    "- **Label Propagation:** Similar to Modularity Optimization in terms of the number of clusters, but it tends to produce one significantly larger community. It's the fastest method but has the lowest modularity, indicating a less precise community structure.\n",
    "\n",
    "Considering these aspects, **Modularity Optimization** seems to be the best method for this particular network. It provides a good balance of computational efficiency, a reasonable number of clusters, and the highest modularity, indicating a strong community structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
