{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instructions\n",
    "0) Treat your graph as undirected and unweighted, and work on the resulting largest connected\n",
    "component. Delete loops\n",
    "1) Create a function computing CN and one of the topological indices between JI,PA,AA,RA.\n",
    "Your function should return a pandaframe where each row is a missing link and each column is\n",
    "an index. You are allowed to use built-in functions from NetworkX for computing individual\n",
    "indices.\n",
    "2) Create a third score by adding a column with the arithmetic mean between the two indices.\n",
    "[NB: the arithmetic mean should be computed after rescaling each column between 0 and 1.]\n",
    "3) For each of the 3 scores, identify as missing links the node pairs yielding the largest 5 values.\n",
    "Briefly comment the results.\n",
    "4) Optional: Invent a new index/score and compare the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of \u001b[1mnodes\u001b[0m in the LCC is: \u001b[1m70\u001b[0m\n",
      "The number of \u001b[1medges\u001b[0m in the LCC is: \u001b[1m299\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_graph(nodes_file_path='../Graph/nodes.csv', edges_file_path='../Graph/edges.csv'):\n",
    "    G = nx.DiGraph()  # Create a directed graph\n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])  # Add nodes to the graph with the label\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_edge(row['Source'], row['Target'], weight=1)  # Add edges to the graph with same weight = 1 (unweighted)\n",
    "\n",
    "    U = G.to_undirected()  # Transform the graph into an undirected\n",
    "    U.remove_edges_from(nx.selfloop_edges(U))  # Remove self loops\n",
    "    \n",
    "    # Check the size of the largest connected component\n",
    "    LCCNodes = list(max(nx.connected_components(U), key=len)) # Get the nodes of the largest connected component\n",
    "    LCC = U.subgraph(LCCNodes)  # Create the largest connected component as a subgraph of the original graph\n",
    "    \n",
    "    print(f\"The number of \\033[1mnodes\\033[0m in the LCC is: \\033[1m{LCC.number_of_nodes()}\\033[0m\")\n",
    "    print(f\"The number of \\033[1medges\\033[0m in the LCC is: \\033[1m{LCC.number_of_edges()}\\033[0m\")\n",
    "\n",
    "    return\n",
    "\n",
    "load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Node1                  Node2  CN   PA\n",
      "0     SEAMAN                MURDOCH   1   12\n",
      "1     SEAMAN                ANATOLY   0    2\n",
      "2     SEAMAN                  BROCK   0    5\n",
      "3     SEAMAN                LOVEJOY   1   19\n",
      "4     SEAMAN  FIRST OFFICER MURDOCH   0    5\n",
      "...      ...                    ...  ..  ...\n",
      "2111   SMITH                HUSBAND   3   75\n",
      "2112    RUTH                  MOODY   2  200\n",
      "2113    RUTH                HUSBAND   5  125\n",
      "2114   MOLLY                HUSBAND   4  115\n",
      "2115   MOODY                HUSBAND   1   40\n",
      "\n",
      "[2116 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_graph(nodes_file_path='../Graph/nodes.csv', edges_file_path='../Graph/edges.csv'):\n",
    "    G = nx.Graph()  # Create empty undirected graph\n",
    "    \n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])  # Add nodes to the graph with the label\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_edge(row['Source'], row['Target'])  # Add edges to the graph\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def compute_CN_PA(graph):\n",
    "    # Get all non-edges from the graph (potential future links)\n",
    "    non_edges = list(nx.non_edges(graph))\n",
    "    \n",
    "    # Calculate Common Neighbors (CN) for each non-edge\n",
    "    CN = [(graph.nodes[u]['label'], graph.nodes[v]['label'], len(list(nx.common_neighbors(graph, u, v)))) for u, v in non_edges]\n",
    "    # Number of common neighbors u and v share for each pair of non-connected nodes\n",
    "    \n",
    "    # Calculate Preferential Attachment (PA) for each non-edge\n",
    "    PA = [(graph.nodes[u]['label'], graph.nodes[v]['label'], graph.degree(u) * graph.degree(v)) for u, v in non_edges]\n",
    "    # Product of the degrees of u and v - so number of connections they have - for each pair of non-connected nodes\n",
    "    \n",
    "    # Convert the results to a dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Node1': [u for u, v, _ in CN],  # Get the first node from the CN list\n",
    "        'Node2': [v for u, v, _ in CN],  # Get the second node from the CN list\n",
    "        'CN': [index for _, _, index in CN],  # Get the number of common neighbors from the CN list\n",
    "        'PA': [index for _, _, index in PA]  # Get the number of neighbors from the PA list\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "graph = load_graph()\n",
    "lcc_nodes = max(nx.connected_components(graph), key=len)  # Get the nodes of the largest connected component\n",
    "lcc = graph.subgraph(lcc_nodes)  # Create the largest connected component as a subgraph of the original graph\n",
    "\n",
    "# Compute metrics on the LCC\n",
    "df = compute_CN_PA(lcc)  # Create the dataframe with the results\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Node1                  Node2  CN   PA  CN_scaled  PA_scaled  Mean_CN_PA\n",
      "0     SEAMAN                MURDOCH   1   12        0.1   0.019964    0.059982\n",
      "1     SEAMAN                ANATOLY   0    2        0.0   0.001815    0.000907\n",
      "2     SEAMAN                  BROCK   0    5        0.0   0.007260    0.003630\n",
      "3     SEAMAN                LOVEJOY   1   19        0.1   0.032668    0.066334\n",
      "4     SEAMAN  FIRST OFFICER MURDOCH   0    5        0.0   0.007260    0.003630\n",
      "...      ...                    ...  ..  ...        ...        ...         ...\n",
      "2111   SMITH                HUSBAND   3   75        0.3   0.134301    0.217151\n",
      "2112    RUTH                  MOODY   2  200        0.2   0.361162    0.280581\n",
      "2113    RUTH                HUSBAND   5  125        0.5   0.225045    0.362523\n",
      "2114   MOLLY                HUSBAND   4  115        0.4   0.206897    0.303448\n",
      "2115   MOODY                HUSBAND   1   40        0.1   0.070780    0.085390\n",
      "\n",
      "[2116 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def rescale(series):\n",
    "    min_val = series.min()  # Get the minimum value of the series\n",
    "    max_val = series.max()  # Get the maximum value of the series\n",
    "    return (series - min_val) / (max_val - min_val)  # Rescale the series, subtracting the minimum and dividing by the difference between the maximum and minimum\n",
    "\n",
    "def add_mean_column(df):\n",
    "    # First, we rescale the 'CN' and 'PA' columns\n",
    "    df['CN_scaled'] = rescale(df['CN'])\n",
    "    df['PA_scaled'] = rescale(df['PA'])\n",
    "\n",
    "    # Then, we compute the arithmetic mean of the scaled values\n",
    "    df['Mean_CN_PA'] = df[['CN_scaled', 'PA_scaled']].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "# Load the graph and extract the LCC\n",
    "graph = load_graph()\n",
    "lcc_nodes = max(nx.connected_components(graph), key=len)\n",
    "lcc = graph.subgraph(lcc_nodes)\n",
    "\n",
    "# Compute CN and PA on the LCC\n",
    "df = compute_CN_PA(lcc)\n",
    "\n",
    "# Add the mean column to the DataFrame\n",
    "df = add_mean_column(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 missing links for the CN index are:\n",
      "\u001b[1mLOVEJOY - MOLLY\u001b[0m\n",
      "\u001b[1mMURDOCH - JACK\u001b[0m\n",
      "\u001b[1mMURDOCH - ROSE\u001b[0m\n",
      "\u001b[1mWOMAN - RUTH\u001b[0m\n",
      "\u001b[1mCAL - SMITH\u001b[0m\n",
      "\n",
      "The top 5 missing links for the PA index are:\n",
      "\u001b[1mMURDOCH - ROSE\u001b[0m\n",
      "\u001b[1mCAL - SMITH\u001b[0m\n",
      "\u001b[1mMURDOCH - JACK\u001b[0m\n",
      "\u001b[1mLOVEJOY - MOLLY\u001b[0m\n",
      "\u001b[1mLOVETT - JACK\u001b[0m\n",
      "\n",
      "The top 5 missing links for the Mean_CN_PA index are:\n",
      "\u001b[1mMURDOCH - ROSE\u001b[0m\n",
      "\u001b[1mMURDOCH - JACK\u001b[0m\n",
      "\u001b[1mCAL - SMITH\u001b[0m\n",
      "\u001b[1mLOVEJOY - MOLLY\u001b[0m\n",
      "\u001b[1mWOMAN - RUTH\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_top_missing_links(df, indices):\n",
    "    predicted_missing_links = {}  # Create an empty dictionary to store the results\n",
    "    for index in indices:\n",
    "        # Sort the DataFrame based on the index in descending order to get the top scores\n",
    "        sorted_df = df.sort_values(by=index, ascending=False).head(5)\n",
    "        # Extract the Node1 and Node2 columns to get the pairs\n",
    "        predicted_missing_links[index] = sorted_df[['Node1', 'Node2']].values.tolist()\n",
    "    return predicted_missing_links\n",
    "\n",
    "# Ensure that the indices are in a list for iteration\n",
    "indices = ['CN', 'PA', 'Mean_CN_PA']\n",
    "\n",
    "# Identify the top missing links for each index\n",
    "top_missing_links = find_top_missing_links(df, indices)\n",
    "\n",
    "# Display the results\n",
    "for index, links in top_missing_links.items():\n",
    "    print(f\"The top 5 missing links for the {index} index are:\")\n",
    "    for link in links:\n",
    "        print(f\"\\033[1m{link[0]} - {link[1]}\\033[0m\")\n",
    "    print('')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
