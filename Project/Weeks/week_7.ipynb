{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instructions\n",
    "0) Treat your graph as undirected and unweighted, and work on the resulting largest connected\n",
    "component. Delete loops\n",
    "1) Create a function computing CN and one of the topological indices between JI,PA,AA,RA.\n",
    "Your function should return a pandaframe where each row is a missing link and each column is\n",
    "an index. You are allowed to use built-in functions from NetworkX for computing individual\n",
    "indices.\n",
    "2) Create a third score by adding a column with the arithmetic mean between the two indices.\n",
    "[NB: the arithmetic mean should be computed after rescaling each column between 0 and 1.]\n",
    "3) For each of the 3 scores, identify as missing links the node pairs yielding the largest 5 values.\n",
    "Briefly comment the results.\n",
    "4) Optional: Invent a new index/score and compare the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in the LCC is: 70\n",
      "The number of edges in the LCC is: 299\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_graph(nodes_file_path, edges_file_path):\n",
    "    G = nx.DiGraph()\n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_edge(row['Source'], row['Target'], weight=1)\n",
    "\n",
    "    U = G.to_undirected()  # Transform the graph into an undirected and unweighted graph\n",
    "    U.remove_edges_from(nx.selfloop_edges(U))  # Remove self loops\n",
    "    \n",
    "    # Check the size of the largest connected component\n",
    "    LCCNodes = list(max(nx.connected_components(U), key=len))\n",
    "    LCC = U.subgraph(LCCNodes)\n",
    "    print(\"The number of nodes in the LCC is:\", LCC.number_of_nodes())\n",
    "    print(\"The number of edges in the LCC is:\", LCC.number_of_edges())\n",
    "load_graph('../Graph/nodes.csv', '../Graph/edges.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Node1    Node2  CN   PA\n",
      "0     GRACIE     BELL   1   90\n",
      "1     GRACIE    BROCK   1   75\n",
      "2     GRACIE     SVEN   1   60\n",
      "3     GRACIE  HUSBAND   3   75\n",
      "4     GRACIE    BUELL   1   90\n",
      "...      ...      ...  ..  ...\n",
      "2111  MOTHER     ROSE   1   92\n",
      "2112  MOTHER      MAN   1   22\n",
      "2113    ROWE   WAITER   2   30\n",
      "2114    ROWE      MAN   2   33\n",
      "2115  WAITER      MAN   4  110\n",
      "\n",
      "[2116 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_graph(nodes_file_path, edges_file_path):\n",
    "    G = nx.Graph()  # Assuming undirected graph\n",
    "    \n",
    "    with open(nodes_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_node(row['Id'], label=row['Label'])\n",
    "\n",
    "    with open(edges_file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            G.add_edge(row['Source'], row['Target'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "def compute_CN_PA(graph):\n",
    "    # Get all non-edges from the graph (potential future links)\n",
    "    non_edges = list(nx.non_edges(graph))\n",
    "    \n",
    "    # Calculate Common Neighbors (CN) for each non-edge\n",
    "    CN = [(graph.nodes[u]['label'], graph.nodes[v]['label'], len(list(nx.common_neighbors(graph, u, v)))) for u, v in non_edges]\n",
    "    \n",
    "    # Calculate Preferential Attachment (PA) for each non-edge\n",
    "    PA = [(graph.nodes[u]['label'], graph.nodes[v]['label'], graph.degree(u) * graph.degree(v)) for u, v in non_edges]\n",
    "    \n",
    "    # Convert the results to a dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Node1': [u for u, v, _ in CN],\n",
    "        'Node2': [v for u, v, _ in CN],\n",
    "        'CN': [index for _, _, index in CN],\n",
    "        'PA': [index for _, _, index in PA]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "graph = load_graph('../Graph/nodes.csv', '../Graph/edges.csv')\n",
    "lcc_nodes = max(nx.connected_components(graph), key=len)\n",
    "lcc = graph.subgraph(lcc_nodes)\n",
    "\n",
    "# Compute metrics on the LCC\n",
    "df = compute_CN_PA(lcc)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Node1    Node2  CN   PA  CN_scaled  PA_scaled  Mean_CN_PA\n",
      "0     GRACIE     BELL   1   90        0.1   0.161525    0.130762\n",
      "1     GRACIE    BROCK   1   75        0.1   0.134301    0.117151\n",
      "2     GRACIE     SVEN   1   60        0.1   0.107078    0.103539\n",
      "3     GRACIE  HUSBAND   3   75        0.3   0.134301    0.217151\n",
      "4     GRACIE    BUELL   1   90        0.1   0.161525    0.130762\n",
      "...      ...      ...  ..  ...        ...        ...         ...\n",
      "2111  MOTHER     ROSE   1   92        0.1   0.165154    0.132577\n",
      "2112  MOTHER      MAN   1   22        0.1   0.038113    0.069056\n",
      "2113    ROWE   WAITER   2   30        0.2   0.052632    0.126316\n",
      "2114    ROWE      MAN   2   33        0.2   0.058076    0.129038\n",
      "2115  WAITER      MAN   4  110        0.4   0.197822    0.298911\n",
      "\n",
      "[2116 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def rescale(series):\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    return (series - min_val) / (max_val - min_val)\n",
    "\n",
    "def add_mean_column(df):\n",
    "    # First, we rescale the 'CN' and 'PA' columns\n",
    "    df['CN_scaled'] = rescale(df['CN'])\n",
    "    df['PA_scaled'] = rescale(df['PA'])\n",
    "\n",
    "    # Then, we compute the arithmetic mean of the scaled values\n",
    "    df['Mean_CN_PA'] = df[['CN_scaled', 'PA_scaled']].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "# Load the graph and extract the LCC\n",
    "graph = load_graph('../Graph/nodes.csv', '../Graph/edges.csv')\n",
    "lcc_nodes = max(nx.connected_components(graph), key=len)\n",
    "lcc = graph.subgraph(lcc_nodes)\n",
    "\n",
    "# Compute CN and PA on the LCC\n",
    "df = compute_CN_PA(lcc)\n",
    "\n",
    "# Add the mean column to the DataFrame\n",
    "df = add_mean_column(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 missing links for the CN index are:\n",
      "MOLLY - LOVEJOY\n",
      "MURDOCH - JACK\n",
      "MURDOCH - ROSE\n",
      "WOMAN - RUTH\n",
      "CAL - SMITH\n",
      "The top 5 missing links for the PA index are:\n",
      "MURDOCH - ROSE\n",
      "CAL - SMITH\n",
      "MURDOCH - JACK\n",
      "MOLLY - LOVEJOY\n",
      "LOVETT - JACK\n",
      "The top 5 missing links for the Mean_CN_PA index are:\n",
      "MURDOCH - ROSE\n",
      "MURDOCH - JACK\n",
      "CAL - SMITH\n",
      "MOLLY - LOVEJOY\n",
      "WOMAN - RUTH\n"
     ]
    }
   ],
   "source": [
    "def find_top_missing_links(df, indices):\n",
    "    predicted_missing_links = {}\n",
    "    for index in indices:\n",
    "        # Sort the DataFrame based on the index in descending order to get the top scores\n",
    "        sorted_df = df.sort_values(by=index, ascending=False).head(5)\n",
    "        # Extract the Node1 and Node2 columns to get the pairs\n",
    "        predicted_missing_links[index] = sorted_df[['Node1', 'Node2']].values.tolist()\n",
    "    return predicted_missing_links\n",
    "\n",
    "# Ensure that the indices are in a list for iteration\n",
    "indices = ['CN', 'PA', 'Mean_CN_PA']\n",
    "\n",
    "# Identify the top missing links for each index\n",
    "top_missing_links = find_top_missing_links(df, indices)\n",
    "\n",
    "# Display the results\n",
    "for index, links in top_missing_links.items():\n",
    "    print(f\"The top 5 missing links for the {index} index are:\")\n",
    "    for link in links:\n",
    "        print(f\"{link[0]} - {link[1]}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
